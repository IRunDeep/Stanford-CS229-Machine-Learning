# 높은 편향 (과소적합, Underfitting): 모델이 너무 단순해서 데이터의 패턴을 제대로 학습하지 못하는 경우입니다. 예를 들어, 비선형적인 데이터에 선형 모델을 적용하면 높은 편향이 발생할 수 있습니다 

# 높은 분산 (과대적합, Overfitting): 모델이 훈련 데이터에 너무 복잡하게 적응하여 새로운 데이터에 대한 일반화 성능이 떨어지는 경우입니다. 예를 들어, 데이터의 모든 점을 통과하는 고차 다항식 모델은 높은 분산을 가질 수 있습니다 

#정규화는 과대적합을 방지하기 위한 기법입니다. 비용 함수에 모델의 복잡도를 나타내는 항을 추가하여 매개변수(가중치)의 크기를 제한하는 방식으로 동작합니다

#람다(λ)의 역할: 정규화의 강도를 조절하는 하이퍼파라미터입니다. 람다가 너무 크면 과소적합. 람다가 0이면 과대적합

#홀드아웃 교차 검증 (Holdout Cross-Validation): 데이터를 훈련 세트와 개발 세트로 나누어, 훈련 세트로 모델을 학습시킨 후 개발 세트로 성능을 평가하여 최적의 모델을 선택하는 간단한 방법입니다 

#K-겹 교차 검증 (K-fold Cross-Validation) 데이터가 적을 때 유용한 방법입니다. 훈련 데이터를 K개의 부분집합으로 나누고, K-1개로 학습한 뒤 나머지 1개로 평가하는 과정을 K번 반복하여 성능을 평균냅니다. 일반적으로 K는 10을 많이 사용합니다
