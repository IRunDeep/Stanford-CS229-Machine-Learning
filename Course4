#퍼셉트론 알고리즘: 역사적으로 중요하며, 로지스틱 회귀와 유사하지만 계단 함수를 사용하는 간단한 분류 알고리즘.

#지수족(Exponential Family): 가우시안, 베르누이 분포 등 다양한 확률 분포를 일반적인 형태로 표현하는 방법
#어떤 문제를 풀 때 "출력 데이터 y가 베르누이 분포를 따른다" 또는 "가우시안 분포를 따른다"고 가정하기만 하면, 지수족이라는 공통 틀 덕분에 동일한 학습 알고리즘(GLM)을 적용할 수 있게 됨.
  
#일반화 선형 모델(Generalized Linear Models, GLM): 지수족을 확장하여 입력 특성을 포함하는 모델로, 다양한 종류의 데이터에 선형 모델을 적용할 수 있게 함.
# 로지스틱 회귀는 "출력이 베르누이 분포를 따른다"고 가정한 GLM의 특수한 한 형태  
  
  
#소프트맥스 회귀(Softmax Regression): 다중 클래스 분류 문제에 사용되며, 각 클래스에 대한 확률을 예측.
#0 또는 1로 분류하는 이진 분류(로지스틱 회귀)를 여러 개의 클래스(예: 개, 고양이, 새)로 분류하는 문제로 확장
#입력 데이터에 대한 연관 점수 계산 후, 점수를 소프트맥스 함수에 통과시켜 총합이 1이 되는 확률벡터로 변환.
#가장 확률이 높은 클래스를 최종 예측 결과로 선택.

  
